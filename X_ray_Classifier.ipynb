{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+XSEdx64PFJXjf77zOPmj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dynamo13007/Delta-Hacks/blob/main/X_ray_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfrpGYwA159U"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import app\n",
        "\n",
        "\n",
        "train_dir = 'path/to/train/directory'\n",
        "test_dir = 'path/to/test/directory'\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255, # rescale pixel values to [0,1]\n",
        "    shear_range=0.2, # apply random shear augmentation\n",
        "    zoom_range=0.2, # apply random zoom augmentation\n",
        "    horizontal_flip=True) # apply horizontal flip augmentation\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224), # resize images to (224,224)\n",
        "    batch_size=32,\n",
        "    color_mode='grayscale', # convert images to grayscale\n",
        "    class_mode='categorical') # multi-class classification\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    color_mode='grayscale',\n",
        "    class_mode='categorical')\n",
        "\n",
        "\n",
        "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_dir = 'path/to/train/directory'\n",
        "test_dir = 'path/to/test/directory'\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255, # rescale pixel values to [0,1]\n",
        "    shear_range=0.2, # apply random shear augmentation\n",
        "    zoom_range=0.2, # apply random zoom augmentation\n",
        "    horizontal_flip=True) # apply horizontal flip augmentation\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224), # resize images to (224,224)\n",
        "    batch_size=32,\n",
        "    color_mode='grayscale', # convert images to grayscale\n",
        "    class_mode='categorical') # multi-class classification\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    color_mode='grayscale',\n",
        "    class_mode='categorical')\n",
        "\n",
        "model.fit(train_generator, epochs=10, validation_data=test_generator)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_generator, epochs=10, validation_data=test_generator)\n",
        "\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Add convolutional layers\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Flatten the output before the dense layers\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Add dense layers\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=keras.optimizers.Adam(lr=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fit the model to the training set and evaluate on the validation set\n",
        "history = model.fit(train_generator, epochs=20, batch_size=32, validation_data=test_generator)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plot cross-entropy loss\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(history.history['loss'], label='train')\n",
        "ax.plot(history.history['val_loss'], label='validation')\n",
        "ax.set_title('Cross-entropy Loss')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Loss')\n",
        "ax.legend()\n",
        "fig.savefig('static/images/loss.png')\n",
        "\n",
        "# plot AUC\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(history.history['auc'], label='train')\n",
        "ax.plot(history.history['val_auc'], label='validation')\n",
        "ax.set_title('AUC')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('AUC')\n",
        "ax.legend()\n",
        "fig.savefig('static/images/auc.png')\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# generate predictions\n",
        "y_pred = model.predict(validation_data)\n",
        "\n",
        "# convert predictions to class labels\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# calculate classification report\n",
        "print(classification_report(validation_data.classes, y_pred))\n",
        "\n",
        "# calculate confusion matrix\n",
        "cm = confusion_matrix(validation_data.classes, y_pred)\n",
        "print(cm)\n"
      ]
    }
  ]
}